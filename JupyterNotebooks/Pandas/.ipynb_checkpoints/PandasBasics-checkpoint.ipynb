{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Hands-on with Pandas: An Iris Dataset Exploration\n",
    "\n",
    "This notebook provides a practical guide to working with the **Pandas** library in Python, using the famous **Iris dataset**. We'll cover fundamental operations from data loading and exploration to manipulation and basic visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Acquisition\n",
    "\n",
    "First, we need to import the necessary libraries: **`pandas`** for data manipulation, **`seaborn`** to easily load the Iris dataset, and **`matplotlib.pyplot`** for basic visualizations.\n",
    "\n",
    "In a real-world scenario, you might load data from a CSV, Excel, or database file using `pd.read_csv()`, `pd.read_excel()`, etc. Here, we'll use `seaborn`'s built-in datasets for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np # Will be used later for handling missing data demonstration\n",
    "\n",
    "# Load the Iris dataset directly from seaborn's built-in datasets\n",
    "df_iris = sns.load_dataset('iris')\n",
    "\n",
    "print(\"Iris Dataset loaded successfully into a Pandas DataFrame!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initial Data Exploration (Getting to Know Your Data)\n",
    "\n",
    "Before diving into analysis, it's crucial to understand the structure, content, and basic statistics of your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the first few rows\n",
    "`df.head()` shows the top N (default 5) rows, giving a quick glance at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- First 5 rows of the DataFrame ---\")\n",
    "print(df_iris.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the last few rows\n",
    "`df.tail()` shows the bottom N (default 5) rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Last 5 rows of the DataFrame ---\")\n",
    "print(df_iris.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a concise summary of the DataFrame\n",
    "`df.info()` provides a summary including the index dtype and column dtypes, non-null values, and memory usage. It's excellent for quickly identifying missing values and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- DataFrame Info ---\")\n",
    "df_iris.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get descriptive statistics for numerical columns\n",
    "`df.describe()` generates descriptive statistics (count, mean, std, min, 25%, 50%, 75%, max) for numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Descriptive Statistics for Numerical Columns ---\")\n",
    "print(df_iris.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the number of rows and columns\n",
    "`df.shape` returns a tuple representing the dimensionality of the DataFrame (rows, columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n--- Shape of the DataFrame ---\")\n",
    "print(f\"Rows: {df_iris.shape[0]}, Columns: {df_iris.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the column names\n",
    "`df.columns` returns an Index object containing the column labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Column Names ---\")\n",
    "print(df_iris.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check unique values and their counts in a categorical column\n",
    "`df['column_name'].unique()` returns an array of unique values in a Series.\n",
    "`df['column_name'].value_counts()` returns a Series containing counts of unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Unique Species in the 'species' column ---\")\n",
    "print(df_iris['species'].unique())\n",
    "\n",
    "print(\"\\n--- Value Counts for each Species ---\")\n",
    "print(df_iris['species'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Selection and Filtering\n",
    "\n",
    "Pandas provides powerful ways to select specific columns, rows, or subsets of data based on conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select a single column (returns a Series)\n",
    "You can access a column using dictionary-like notation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- 'sepal_length' column (first 5 values) ---\")\n",
    "print(df_iris['sepal_length'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select multiple columns (returns a DataFrame)\n",
    "Pass a list of column names to select multiple columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- 'sepal_length' and 'petal_length' columns (first 5 rows) ---\")\n",
    "print(df_iris[['sepal_length', 'petal_length']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select rows using `.loc[]` (label-based indexing)\n",
    "`loc` is used for selection by label. You can select rows by their index labels and columns by their column labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Rows with index labels 0 to 2 (all columns) using .loc ---\")\n",
    "print(df_iris.loc[0:2]) # Inclusive range for labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select rows using `.iloc[]` (integer-location based indexing)\n",
    "`iloc` is used for selection by integer position. It behaves like standard Python slicing (exclusive of the end index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- First 3 rows, first 2 columns using .iloc ---\")\n",
    "print(df_iris.iloc[0:3, 0:2]) # Rows 0, 1, 2; Columns 0, 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter rows based on a single condition\n",
    "This creates a boolean Series, which is then used to select rows where the condition is `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Data for 'setosa' species ---\")\n",
    "setosa_df = df_iris[df_iris['species'] == 'setosa']\n",
    "print(setosa_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter with multiple conditions\n",
    "Combine conditions using `&` (AND) or `|` (OR). Remember to wrap each condition in parentheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- 'virginica' species with petal_length greater than 5.0 ---\")\n",
    "filtered_df = df_iris[(df_iris['species'] == 'virginica') & (df_iris['petal_length'] > 5.0)]\n",
    "print(filtered_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Manipulation and Aggregation\n",
    "\n",
    "Pandas allows for easy creation of new columns, grouping data, and performing aggregate calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new column\n",
    "New columns can be created by performing operations on existing columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris['sepal_area'] = df_iris['sepal_length'] * df_iris['sepal_width']\n",
    "print(\"\\n--- DataFrame with new 'sepal_area' column (first 5 rows) ---\")\n",
    "print(df_iris.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group data and calculate aggregates\n",
    "`groupby()` is one of the most powerful Pandas features, allowing you to split data into groups based on some criteria and then apply a function (e.g., `mean()`, `sum()`, `count()`) to each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Mean values for all numerical columns, grouped by species ---\")\n",
    "print(df_iris.groupby('species').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group by a column and apply multiple aggregate functions to a specific column\n",
    "Use `.agg()` after `groupby()` to apply different aggregate functions to one or more columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Petal Length statistics (mean and standard deviation) by species ---\")\n",
    "print(df_iris.groupby('species')['petal_length'].agg(['mean', 'std']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort the DataFrame\n",
    "`sort_values()` sorts the DataFrame by one or more columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- DataFrame sorted by 'sepal_length' in descending order (first 5 rows) ---\")\n",
    "print(df_iris.sort_values(by='sepal_length', ascending=False).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop a column\n",
    "`drop()` removes specified rows or columns. `axis=1` indicates columns, `axis=0` indicates rows. `inplace=True` modifies the DataFrame directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iris.drop(columns=['sepal_area'], inplace=True)\n",
    "print(\"\\n--- DataFrame after dropping 'sepal_area' column (first 5 rows) ---\")\n",
    "print(df_iris.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Handling Missing Data (Illustrative Example)\n",
    "\n",
    "Real-world datasets often have missing values. Pandas provides robust tools to detect and handle them. The Iris dataset is very clean, so we'll artificially introduce some **`NaN` (Not a Number)** values to demonstrate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a temporary copy and introduce NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary copy to avoid modifying the original df_iris\n",
    "df_temp = df_iris.copy()\n",
    "\n",
    "# Introduce NaN in 'sepal_width' for rows 5 to 10\n",
    "df_temp.loc[5:10, 'sepal_width'] = np.nan\n",
    "# Introduce NaN in 'petal_length' for rows 20 to 25\n",
    "df_temp.loc[20:25, 'petal_length'] = np.nan\n",
    "\n",
    "print(\"\\n--- DataFrame with Artificial Missing Values (first 30 rows) ---\")\n",
    "print(df_temp.head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for missing values\n",
    "`isnull()` returns a boolean DataFrame indicating missing values. `sum()` counts them per column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Count of Missing values per column ---\")\n",
    "print(df_temp.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill missing values\n",
    "`fillna()` replaces missing values. Common strategies include filling with the mean, median, mode, or a specific constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in 'sepal_width' with its mean\n",
    "mean_sepal_width = df_temp['sepal_width'].mean()\n",
    "df_temp['sepal_width'].fillna(mean_sepal_width, inplace=True)\n",
    "print(f\"\\n--- 'sepal_width' after filling NaNs with mean ({mean_sepal_width:.2f}) (first 30 rows) ---\")\n",
    "print(df_temp.head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop rows with missing values\n",
    "`dropna()` removes rows or columns containing missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how many NaNs are left before dropping (petal_length still has NaNs)\n",
    "print(\"\\n--- Missing values count before dropping NaNs ---\")\n",
    "print(df_temp.isnull().sum())\n",
    "\n",
    "df_temp.dropna(inplace=True) # Drops rows where 'petal_length' is still NaN\n",
    "print(\"\\n--- DataFrame after dropping rows with any remaining missing values ---\")\n",
    "print(df_temp.isnull().sum()) # Should show 0 for all columns\n",
    "print(f\"New shape after dropping rows with NaNs: {df_temp.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Basic Data Visualization\n",
    "\n",
    "Pandas DataFrames integrate well with `matplotlib` and `seaborn` for quick and insightful visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter Plot: Sepal Length vs Sepal Width, colored by species\n",
    "A scatter plot helps visualize the relationship between two numerical variables and how a third categorical variable (species) might influence it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Generating Scatter Plot: Sepal Length vs Sepal Width ---\")\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x='sepal_length', y='sepal_width', hue='species', data=df_iris, s=100, alpha=0.8)\n",
    "plt.title('Sepal Length vs Sepal Width by Species (Iris Dataset)')\n",
    "plt.xlabel('Sepal Length (cm)')\n",
    "plt.ylabel('Sepal Width (cm)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box Plot: Petal Length Distribution by Species\n",
    "A box plot is excellent for showing the distribution (median, quartiles, outliers) of a numerical variable across different categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Generating Box Plot: Petal Length Distribution by Species ---\")\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x='species', y='petal_length', data=df_iris)\n",
    "plt.title('Petal Length Distribution by Species (Iris Dataset)')\n",
    "plt.xlabel('Species')\n",
    "plt.ylabel('Petal Length (cm)')\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook provided a hands-on introduction to Pandas using the Iris dataset. You've learned how to:\n",
    "- Load data into a DataFrame.\n",
    "- Perform initial data exploration (`head`, `tail`, `info`, `describe`, `shape`, `columns`, `unique`, `value_counts`).\n",
    "- Select and filter data using `.loc[]`, `.iloc[]`, and boolean indexing.\n",
    "- Manipulate data by creating new columns, grouping, aggregating, and sorting.\n",
    "- Illustrate handling of missing data (filling and dropping).\n",
    "- Create basic visualizations to gain insights from your data.\n",
    "\n",
    "To continue improving your Pandas skills, I highly recommend downloading other real-world datasets from platforms like Kaggle, UCI Machine Learning Repository, or Data.gov, and applying these techniques. Each new dataset will present unique challenges and learning opportunities!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
