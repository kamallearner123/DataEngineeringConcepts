{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60a83021-a6e8-4cd1-ab44-705762429b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "redshift-connector==2.1.8\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep redshift-connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f71c9d-d3c9-4f95-84a3-a8c5f24f4245",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Default IAM role\n",
    "arn:aws:iam::310879042055:role/service-role/AmazonRedshift-CommandsAccessRole-20250703T183658\n",
    "IAM roles\n",
    "arn:aws:iam::310879042055:role/service-role/AmazonRedshift-CommandsAccessRole-20250703T183658'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cadc9ef6-be29-4d27-8fe1-15b1a105a409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error connecting to Redshift Serverless: connect() got an unexpected keyword argument 'workgroup_name'\n",
      "Ensure your AWS credentials are configured (e.g., via aws configure),\n",
      "your security group allows access, and IAM permissions are correct.\n"
     ]
    }
   ],
   "source": [
    "import redshift_connector\n",
    "\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import boto3 # For S3 operations\n",
    "\n",
    "# --- Redshift Serverless and S3 Configuration (replace with your actual details) ---\n",
    "AWS_REGION = 'us-east-1' # Your AWS region\n",
    "REDSHIFT_SERVERLESS_WORKGROUP_NAME = 'demo-workgroup-01'\n",
    "REDSHIFT_SERVERLESS_DB_NAME = 'dev' # Or your specific database name\n",
    "# If using IAM Role for the executing environment (e.g., EC2, Lambda),\n",
    "# you typically don't need access_key_id/secret_access_key here.\n",
    "# redshift_connector will pick up credentials from env vars, ~/.aws/credentials, or IAM role.\n",
    "# For local testing without an IAM role:\n",
    "# AWS_ACCESS_KEY_ID = 'YOUR_AWS_ACCESS_KEY_ID'\n",
    "# AWS_SECRET_ACCESS_KEY = 'YOUR_AWS_SECRET_ACCESS_KEY'\n",
    "\n",
    "S3_KEY_PREFIX = 'serverless-data-uploads/'\n",
    "# S3 bucket for COPY/UNLOAD (must exist and have Redshift role access)\n",
    "S3_BUCKET_NAME = 'kkm2-unique-test-bucket-2025-06-26-py-1'\n",
    "S3_FILE_TO_UNLOAD = 'redshift_sample.csv'\n",
    "S3_UNLOAD_PATH = f's3://{S3_BUCKET_NAME}/{S3_FILE_TO_UNLOAD}'\n",
    "S3_COPY_PATH = f's3://{S3_BUCKET_NAME}/flights.csv' # Path to your existing sample data\n",
    "\n",
    "# IAM Role ARN for Redshift to access S3 (must have s3:GetObject on your bucket)\n",
    "# This is attached to your Redshift Serverless namespace.\n",
    "IAM_ROLE_ARN_FOR_COPY = 'arn:aws:iam::123456789012:role/YourRedshiftServerlessCopyRole'\n",
    "\n",
    "def get_redshift_serverless_connection():\n",
    "    \"\"\"Establishes a connection to Amazon Redshift Serverless using IAM authentication.\"\"\"\n",
    "    try:\n",
    "        conn = redshift_connector.connect(\n",
    "            workgroup_name=REDSHIFT_SERVERLESS_WORKGROUP_NAME,\n",
    "            database=REDSHIFT_SERVERLESS_DB_NAME,\n",
    "            iam=True,\n",
    "            region=AWS_REGION\n",
    "            # ... other parameters\n",
    "        )\n",
    "        print(\"Successfully connected to Redshift Serverless!\")\n",
    "        return conn\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to Redshift Serverless: {e}\")\n",
    "        print(\"Ensure your AWS credentials are configured (e.g., via aws configure),\")\n",
    "        print(\"your security group allows access, and IAM permissions are correct.\")\n",
    "        return None\n",
    "\n",
    "def list_redshift_databases(conn):\n",
    "    \"\"\"Lists all databases in the Redshift Serverless workgroup.\"\"\"\n",
    "    if not conn:\n",
    "        print(\"No active connection to Redshift.\")\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        with conn.cursor() as cursor:\n",
    "            # For Redshift Serverless, querying pg_database will show available databases within the namespace\n",
    "            cursor.execute(\"SELECT datname FROM pg_database;\")\n",
    "            databases = [row[0] for row in cursor.fetchall()]\n",
    "            print(\"\\nRedshift Serverless Databases:\")\n",
    "            for db in databases:\n",
    "                print(f\"- {db}\")\n",
    "            return databases\n",
    "    except Exception as e:\n",
    "        print(f\"Error listing databases: {e}\")\n",
    "        return []\n",
    "get_redshift_serverless_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd4e766-b432-40f4-af7c-5037407a806e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (DeepCode)",
   "language": "python",
   "name": "deepcode"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
